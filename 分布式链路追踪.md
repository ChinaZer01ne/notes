# 分布式链路追踪



## 什么是链路追踪

​		随着项目的分布式微服务化，整体的调用链变得越来越复杂。当接口出现问题时，很难从错综复杂的服务调用网络中找到问题根源。

​		分布式链路追踪就是将一次分布式请求还原成调用链路，将一次分布式请求的调用情况集中展示，比如各个服务节点上的耗时、请求具体到达哪台机器上、每个服务节点的请求状态等等。



## 基本原理

​		目前分布式链路追踪系统基本都是根据谷歌的[《Dapper大规模分布式系统的跟踪系统》](http://bigbully.github.io/Dapper-translation/)这篇论文发展而来，主流的有`zipkin`，`pinpoint`，`skywalking`，`cat`等。

​		如果想知道一个接口在哪个环节出现了问题，就必须清楚该接口调用了哪些服务，以及调用的顺序，如果把这些服务串起来，看起来就像链条一样，我们称其为调用链。

​		想要实现调用链，就要为每次调用做个标识，然后将服务按标识大小排列，可以更清晰地看出调用顺序，我们暂且将该标识命名为`spanid`。

![img](https://upload-images.jianshu.io/upload_images/18344517-bb7538905255adc5.png)

​		实际场景中，我们需要知道某次请求调用的情况，所以只有`spanid`还不够，得为每次请求做个唯一标识，这样才能根据标识查出本次请求调用的所有服务，而这个标识我们命名为`traceid`。

  

![](https://upload-images.jianshu.io/upload_images/18344517-dbb1440684362282.png)

​		现在根据`spanid`可以轻易地知道被调用服务的先后顺序，但无法体现调用的层级关系，正如下图所示，多个服务可能是逐级调用的链条，也可能是同时被同一个服务调用。

![](https://upload-images.jianshu.io/upload_images/18344517-a95c6f4b89781de0.png)

​		到现在，已经知道调用顺序和层级关系了，但是接口出现问题后，还是不能找到出问题的环节，如果某个服务有问题，那个被调用执行的服务一定耗时很长，要想计算出耗时，上述的三个标识还不够，还需要加上时间戳，时间戳可以更精细一点，精确到微秒级。

​			![](https://upload-images.jianshu.io/upload_images/18344517-6b00a6ac37fce128.png)

​		只记录发起调用时的时间戳还算不出耗时，要记录下服务返回时的时间戳，有始有终才能算出时间差，既然返回的也记了，就把上述的三个标识都记一下吧，不然区分不出是谁的时间戳。

​		![](https://upload-images.jianshu.io/upload_images/18344517-9fdfcca49ec1520c.png)

​		更加详细内容，[一文读懂链路追踪](https://juejin.im/post/5cf943875188251346598949)。



## 技术选型

​		由于`zipkin`和`cat`对代码有一定的侵入性，暂时不考虑这两套方案。`pinpoint`和`skywalking`都是基于字节码注入技术，可以做到完全的代码无侵入。他们的对比信息如下：

|                 | Pinpoint                       | Skywalking                             |
| --------------- | ------------------------------ | -------------------------------------- |
| 项目发起人      | Woonduk Kang（韩国）           | 吴晟（中国）                           |
| GitHub Star     | 9.5K                           | 11.2K                                  |
| 社区            | 非apache + 一般                | apache孵化 + 活跃                      |
| 兼容OpenTracing | 否                             | 是                                     |
| 支持语言        | Java，PHP                      | Java，C#，PHP，Node.js                 |
| 协议            | thrift                         | gRPC                                   |
| 存储            | HBase + Mysql                  | ES，H2，Mysql，TiDB，Sharding-Sphere   |
| 扩展性          | 低                             | 高                                     |
| TraceId查询     | 不支持                         | 支持                                   |
| 实现方式        | 字节码注入                     | 字节码注入                             |
| 告警            | 支持                           | 支持                                   |
| JVM监控         | 支持                           | 支持                                   |
| 跟踪粒度        | 细                             | 一般                                   |
| 过滤追踪        | filter配置                     | agent.config + apm-trace-ignore-plugin |
| 性能损耗        | 高                             | 低                                     |
| 组件            | collector + Web + agent + 存储 | OAP+ Web + agent + 存储 + zk           |
| 发布包          | war                            | jar                                    |



​		有关于这两套方案的详细比较，笔者建议大家看一下这一篇文章[APM巅峰对决：skywalking P.K. Pinpoint](http://skywalking.apache.org/zh/blog/2019-02-24-skywalking-pk-pinpoint.html)。

​		

​		**总结**

​		Pinpoint的优势在于：追踪数据粒度非常细、功能强大的用户界面，以及使用HBase作为存储带来的海量存储能力。而skywalking的优势在于：非常活跃的中文社区，支持多种语言的探针，对国产开源软件非常全面的支持，以及使用es作为底层存储带来的强大的检索能力，并且skywalking的扩展性以及定制化要更优于Pinpoint。



## SkyWalking

### 架构

![](https://upload-images.jianshu.io/upload_images/15663120-ab43393c1788a322.png)



`Skywalking Agent`： 使用 JavaAgent 做字节码植入，无侵入式的收集，并通过 HTTP 或者 gRPC 方式发送数据到 SkyWalking Collector。

`SkyWalking Collector`： 链路数据收集器，对 agent 传过来的数据进行整合分析处理并落入相关的数据存储中。

`Storage`： SkyWalking 的存储，时间更迭，SW 已经开发迭代到了 6.x 版本，在 6.x 版本中支持以 ElasticSearch(支持 6.x)、Mysql、TiDB、H2、作为存储介质进行数据存储。

`UI`： Web 可视化平台，用来展示落地的数据。





### 安装

#### 环境

1、`JDK8`：笔者用11以上，不兼容

2、`Elasticsearch：6.7.0`（6.X版本应该都可以）

3、`SkyWalking：6.1`



#### Elasticsearch安装

docker部署：

```shell
# 1、镜像拉取
$ docker pull elasticsearch:6.5.4
# 2、运行
docker run --name es -p 9200:9200 -p 9300:9300  -e "discovery.type=single-node" [镜像id]
# 3、修改elasticsearch.yml ，
cluster.name: "es" # 此处的名字需要与skywalking中的名称相同
network.host: 0.0.0.0
# 4、重启es
docker restart es
```



#### SkyWalking部署

1、下载

http://skywalking.apache.org/zh/downloads/

2、解压

3、修改配置

①修改`apache-skywalking-apm-bin/config`路径下的`application.yml`，主要是将`storage:h2`注释，采用`storage:elasticsearch:`。注意：`storage:elasticsearch.nameSpace`需要与es的`cluster.name`相同。

```yaml
cluster:
  standalone:
core:
  default:
    role: ${SW_CORE_ROLE:Mixed} # Mixed/Receiver/Aggregator
    restHost: ${SW_CORE_REST_HOST:192.168.1.106}
    restPort: ${SW_CORE_REST_PORT:12800}
    restContextPath: ${SW_CORE_REST_CONTEXT_PATH:/}
    gRPCHost: ${SW_CORE_GRPC_HOST:192.168.1.106}
    gRPCPort: ${SW_CORE_GRPC_PORT:11800}
    downsampling:
    - Hour
    - Day
    - Month
    recordDataTTL: ${SW_CORE_RECORD_DATA_TTL:90} # Unit is minute
    minuteMetricsDataTTL: ${SW_CORE_MINUTE_METRIC_DATA_TTL:90} # Unit is minute
    hourMetricsDataTTL: ${SW_CORE_HOUR_METRIC_DATA_TTL:36} # Unit is hour
    dayMetricsDataTTL: ${SW_CORE_DAY_METRIC_DATA_TTL:45} # Unit is day
    monthMetricsDataTTL: ${SW_CORE_MONTH_METRIC_DATA_TTL:18} # Unit is month
storage:
  elasticsearch:
    nameSpace: ${SW_NAMESPACE:"es"}
    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:192.168.1.106:9200}
    user: ${SW_ES_USER:""}
    password: ${SW_ES_PASSWORD:""}
    indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}
    indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}

receiver-sharing-server:
  default:
receiver-register:
  default:
receiver-trace:
  default:
    bufferPath: ${SW_RECEIVER_BUFFER_PATH:../trace-buffer/}  # Path to trace buffer files, suggest to use absolute path
    bufferOffsetMaxFileSize: ${SW_RECEIVER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB
    bufferDataMaxFileSize: ${SW_RECEIVER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB
    bufferFileCleanWhenRestart: ${SW_RECEIVER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}
    sampleRate: ${SW_TRACE_SAMPLE_RATE:10000} # The sample rate precision is 1/10000. 10000 means 100% sample in default.
    slowDBAccessThreshold: ${SW_SLOW_DB_THRESHOLD:default:200,mongodb:100} # The slow database access thresholds. Unit ms.
receiver-jvm:
  default:
receiver-clr:
  default:
service-mesh:
  default:
    bufferPath: ${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path
    bufferOffsetMaxFileSize: ${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB
    bufferDataMaxFileSize: ${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB
    bufferFileCleanWhenRestart: ${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}
istio-telemetry:
  default:
envoy-metric:
  default:

query:
  graphql:
    path: ${SW_QUERY_GRAPHQL_PATH:/graphql}
alarm:
  default:
telemetry:
  none:

```



②修改`apache-skywalking-apm-bin/webapp`路径下的`webapp.yml`文件。将`collector:ribbon:listOfServers`修改成自己的ip地址。

```shell
server:
  port: 8080
collector:
  path: /graphql
  ribbon:
    ReadTimeout: 10000
    # Point to all backend's restHost:restPort, split by ,
    listOfServers: 192.168.1.106:12800
security:
  user:
    # username
    admin:
      # password
      password: admin
```



4、启动

在`apache-skywalking-apm-bin/bin`下执行

```shell
$ ./startup.sh 
```



5、访问`http://localhost:8080`，默认端口可以在``apache-skywalking-apm-bin/webapp/webapp.yml`中修改。



### Java-agent探针使用

idea中使用方式：

在需要监控的程序中增加虚拟机参数

```properties
# skywalking-agent.jar的绝对路径
-javaagent:/home/peach/software/apache-skywalking-apm-bin/agent/skywalking-agent.jar
-Dskywalking.agent.service_name=xxx
# 或者将apache-skywalking-apm-bin/agent/config/agent.conf中的ip地址替换成实际的ip地址
-Dskywalking.collector.backend_service=192.168.1.106:11800
```



jar包使用方式：

```shell
java -javaagent:/home/peach/software/apache-skywalking-apm-bin/agent/skywalking-agent.jar  -jar xxx.jar
```

