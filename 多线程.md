# 多线程



##概念

**并发**：同时拥有两个或者多个线程，如果程序在单核处理器上运行，多个线程将交替的换入或者换出内存，这些线程是同时“存在”的，每个线程都处于执行过程中的某个状态，如果运行在多核处理器上，此时，程序中的每个线程都将分配到一个处理器上，因此可以同时运行。

> 并发的关注点是：多个线程操作相同的资源，保证线程安全，合理使用资源。

**高并发（High Concurrency）**：是互联网分布式系统架构设计中必须考虑的因素之一，他通常指，通过设计保证系统能够**同时并行处理**很多请求。

> 高并发的关注点是：服务能同时处理很多请求，提高程序性能。



## CPU高速缓存



### CPU的多级缓存



CPU缓存（Cache Memory）是位于CPU与内存之间的临时存储器，它的容量比内存小的多但是交换速度却比内存要快得多。

CPU高速缓存的出现是为了解决主存的读写速度和CPU运算速度之间的不匹配的问题。

CPU有三级缓存，关于该部分内容，[详细内容请看这篇博客](https://blog.csdn.net/huayushuangfei/article/details/80717815)



####带有高速缓存的CPU执行计算流程

1. 程序以及数据被加载到主内存
2. 指令和数据被加载到CPU的高速缓存
3. CPU执行指令，把结果写到高速缓存
4. 高速缓存中的数据写回主内存

![CPU高速缓存执行流程](images/多线程/CPU高速缓存执行流程.png)



#### 目前流行的多级缓存结构

由于CPU的运算速度超越了1级缓存的数据I\O能力，CPU厂商又引入了多级的缓存结构。

![CPU多级缓存架构](images/多线程/CPU多级缓存架构.png)



### 缓存局部性原理



局部性原理是缓存技术的底层理论基础。局部性包含两种形式：

1. **时间局部性**，一个具有良好时间局部性的程序中。被引用过一次的存储器位置非常可能在不远的将来再被多次引用。

2. **空间局部性**，一个具有良好空间局部性的程序中，假设一个存储器位置被引用了一次，那么程序非常可能在不远的将来引用附近的一个存储器位置。



### 缓存一致性（MESI）



​	多核CPU的情况下有多个一级缓存，如何保证缓存内部数据的一致,不让系统数据混乱。用于保证多个CPU cache之间缓存共享数据的一致。



#### MESI协议缓存状态

MESI是指4种状态的首字母。每个Cache line有4个状态，可用2个bit表示：

> 缓存行（Cache line）：缓存存储数据的单元。

| 状态                     | 描述                                                         | 监听任务                                                     |
| ------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| M 修改 (Modified)        | 该Cache line有效，数据被修改了，和内存中的数据不一致，数据只存在于本Cache中。 | 缓存行必须时刻监听所有试图读该缓存行相对于主存的操作，这种操作必须被延迟到缓存将该缓存行写回主存并将状态变成S（共享）状态之后。 |
| E 独享、互斥 (Exclusive) | 该Cache line有效，数据和内存中的数据一致，数据只存在于本Cache中。 | 缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S（共享）状态。 |
| S 共享 (Shared)          | 该Cache line有效，数据和内存中的数据一致，数据存在于很多Cache中。 | 缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）。 |
| I 无效 (Invalid)         | 该Cache line无效。                                           | 无                                                           |



####协议状态转换

![MESI协议状态变化图](images/多线程/MESI协议状态变化图.png)

​	在上图中，`Local Read`表示本内核读本Cache中的值，`Local Write`表示本内核写本Cache中的值，`Remote Read`表示其它内核读其它Cache中的值，`Remote Write`表示其它内核写其它Cache中的值，箭头表示本Cache line状态的迁移，环形箭头表示状态不变。



####MESI状态之间的迁移过程

| 当前状态     | 事件         | 行为                                                         | 下一个状态 |
| ------------ | ------------ | ------------------------------------------------------------ | ---------- |
| I(Invalid)   | Local Read   | 如果其它Cache没有这份数据，本Cache从内存中取数据，Cache line状态变成E； 如果其它Cache有这份数据，且状态为M，则将数据更新到内存，本Cache再从内存中取数据，2个Cache 的Cache line状态都变成S； 如果其它Cache有这份数据，且状态为S或者E，本Cache从内存中取数据，这些Cache 的Cache line状态都变成S | E/S        |
|              | Local Write  | 从内存中取数据，在Cache中修改，状态变成M； 如果其它Cache有这份数据，且状态为M，则要先将数据更新到内存； 如果其它Cache有这份数据，则其它Cache的Cache line状态变成I | M          |
|              | Remote Read  | 既然是Invalid，别的核的操作与它无关                          | I          |
|              | Remote Write | 既然是Invalid，别的核的操作与它无关                          | I          |
| E(Exclusive) | Local Read   | 从Cache中取数据，状态不变                                    | E          |
|              | Local Write  | 修改Cache中的数据，状态变成M                                 | M          |
|              | Remote Read  | 数据和其它核共用，状态变成了S                                | S          |
|              | Remote Write | 数据被修改，本Cache line不能再使用，状态变成I                | I          |
| S(Shared)    | Local Read   | 从Cache中取数据，状态不变                                    | S          |
|              | Local Write  | 修改Cache中的数据，状态变成M， 其它核共享的Cache line状态变成I | M          |
|              | Remote Read  | 状态不变                                                     | S          |
|              | Remote Write | 数据被修改，本Cache line不能再使用，状态变成I                | I          |
| M(Modified)  | Local Read   | 从Cache中取数据，状态不变                                    | M          |
|              | Local Write  | 修改Cache中的数据，状态不变                                  | M          |
|              | Remote Read  | 这行数据被写到内存中，使其它核能使用到最新的数据，状态变成S  | S          |
|              | Remote Write | 这行数据被写到内存中，使其它核能使用到最新的数据，由于其它核会修改这行数据， 状态变成I | I          |



[参考](https://blog.csdn.net/cl2010abc/article/details/80745185)



### CPU乱序执行优化

​	处理器为提高运算速度而做出违背代码原有顺序的优化。比如下面，在多核时代CPU的乱序优化会带来一些问题。

```shell
# 优化前
a = 10;
b = 20;
result = a * b;

# 优化后
b = 20;
a = 10;
result = a * b;
```





## Java内存模型

​	

​	在处理器层面上，内存模型定义了一个充要条件，“让当前的处理器可以看到其他处理器写入到内存的数据”以及“其他处理器可以看到当前处理器写入到内存的数据”。

​	Java内存模型（Java Memory model，JMM），他是一种规范。描述了在多线程代码中哪些行为是合法的，以及线程如何通过内存进行交互，它描述了“程序中的变量”和“从内存或者寄存器获取或存储它们的底层细节”之间的关系。Java内存模型通过使用各种各样的硬件和编译器的优化来正确实现以上事情。

​	由于CPU的CPU缓存以及乱序执行优化导致的指令重排的导致了一些问题。所以就需要Java内存模型规范来解决。它规范了Java虚拟机和内存是如何协同工作的。



### JMM抽象结构图

![JMM抽象结构图](images/多线程/JMM抽象结构图.png)

​	在多线程环境下，多线程访问同一个资源的时候，他们是各自持有了一份资源的私有copy，也就是上图中的共享变量副本。

​	Java多线程中，每个线程都有自己的工作内存，需要和主存进行交互。这里的工作内存和计算机硬件的缓存并不是一回事儿，只是可以相互类比。所以，并发编程的可见性问题，是因为各个线程之间的本地内存数据不一致导致的，和计算机缓存并无关系。



### 原子性操作与内存操作规则



#### 八种原子性操作



**lock（锁定）**：作用于主内存，它把一个变量标记为一条线程独占状态；

**read（读取）**：作用于主内存，它把变量值从主内存传送到线程的工作内存中，以便随后的load动作使用；

**load（载入）**：作用于工作内存，它把read操作的值放入工作内存中的变量副本中；

**use（使用）**：作用于工作内存，它把工作内存中的值传递给执行引擎，每当虚拟机遇到一个需要使用这个变量的指令时候，将会执行这个动作；

**assign（赋值）**：作用于工作内存，它把从执行引擎获取的值赋值给工作内存中的变量，每当虚拟机遇到一个给变量赋值的指令时候，执行该操作；

**store（存储）**：作用于工作内存，它把工作内存中的一个变量传送给主内存中，以备随后的write操作使用；

**write（写入）**：作用于主内存，它把store传送值放到主内存中的变量中。

**unlock（解锁）**：作用于主内存，它将一个处于锁定状态的变量释放出来，释放后的变量才能够被其他线程锁定；



#### 原子性操作规则



Java内存模型还规定了执行上述8种基本操作时必须满足如下规则:

1、不允许read和load、store和write操作之一单独出现（即不允许一个变量从主存读取了但是工作内存不接受，或者从工作内存发起写操作但是主存不接受的情况），以上两个操作必须按顺序执行，但没有保证必须连续执行，也就是说，read与load之间、store与write之间是可插入其他指令的。

2、不允许一个线程丢弃它的最近的assign操作，即变量在工作内存中改变了之后必须把该变化同步回主内存。

3、不允许一个线程无原因地（没有发生过任何assign操作）把数据从线程的工作内存同步回主内存中。

4、一个新的变量只能从主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量，换句话说就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。

5、一个变量在同一个时刻只允许一条线程对其执行lock操作，但lock操作可以被同一个条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁（重入）。

6、如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值。

7、如果一个变量实现没有被lock操作锁定，则不允许对它执行unlock操作，也不允许去unlock一个被其他线程锁定的变量。

8、对一个变量执行unlock操作之前，必须先把此变量同步回主内存（执行store和write操作）。



## 原子性



​	**原子性**就是指该操作是不可再分的。单纯的原子性也不能保证线程安全，需要整体的原子性操作，才能保证线程安全。**比如说两条语句，每一句都是原子性操作，但是多线程的情况，可能会在语句之间进来，依然线程不安全**。



### Java中的原子操作



* 除long和double之外的基本类型的赋值操作
* 所有引用reference的赋值操作
* `java.concurrent.Atomic.* `包中所有类的一切操作。	



### Java实现原子性操作方式



#### Synchronized

1、修饰代码块：大括号括起来的代码，作用于调用的对象

2、修饰方法：整个方法，作用于调用的对象

3、修饰静态方法：整个静态方法，作用于类



#### Lock



#### Atomic



### 不同实现方式的区别



**Synchronized**：不可中断锁，竞争激烈的时候性能下降，不过JDK8中做了优化，实际和Lock差不多，可读性好。

**Lock**：可中断锁，多样化同步，竞争激烈时能维持常态。

**Atomic**：竞争激烈时能维持常态，比Lock性能好；只能同步一个值。





## 有序性



​	有序性即程序执行的顺序按照代码的先后顺序执行。在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。（例如：重排的时候某些赋值会被提前），这一点在[CPU高速缓存](#CPU乱序执行优化)已经介绍过了。

​	在Java里面，可以通过`volatile`关键字来保证一定的“有序性”。另外可以通过`synchronized`和`Lock`来保证有序性，很显然`synchronized`和`Lock`保证每个时刻是仅有一个线程执行同步代码，相当于是让线程顺序执行同步代码，这样就无所谓指令重排了。这里需要注意的是，`synchronized`是无法禁止指令重排和处理器优化的。

​	Java虚拟机天生存在一些有序性规则，会根据是否符合`happens-before`原则，来确定是否对指令进行重排序优化。如果符合，则不对指令进行重排序优化，否则虚拟机无法保证有序性，会对其进行随意的重排序。



### happens-before原则

1. **程序次序规则**：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写后面的操作。（这里说的是具有依赖性的代码，如果代码之间不存在依赖性，那么还是会出现指令重排序的情况，这条规则是用来保证单线程的执行的有序性）
2. **锁定规则**：一个`unlock`操作先行发生于后面对同一个锁的`lock`操作。
3. **volatile变量原则**：对一个变量的写操作先行发生于后面对这个变量的读操作。
4. **传递规则**：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C。
5. **线程启动规则**：Thread对象的`start()`方法先行发生于此线程的每一个动作。
6. **线程中断规则**：对线程`interrupt()`方法的调用先行发生于被中断线程的代码检测到中断事件的发生。
7. **线程终结规则**：线程中所有的操作都先行发生于线程的终止检测，我们可以通过`Thread.join()`方法结束、`Thread.isAlive()`的返回值手段检测到线程已经终止执行。
8. **对象终结规则**：一个对象的初始化完成先行发生于他的`finalize()`方法的开始。



## 可见性



​	**可见性**是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

​	

###共享变量在线程间不可见的原因

* 线程交叉执行。
* 重排序结合线程交叉执行。
* 共享变量更新后的值没有在工作内存与主存间及时更新。



### Java中实现可见性



​	Java提供了`volatile`关键字来保证可见性。单纯的volatile只保证了内存可见性，还需要操作是原子性（8种原子性操作）的，才能保证线程的安全。

​	当一个共享变量被`volatile`修饰时，他会保证修改的值会立即被更新到主存，当其他线程需要读取时，他会去内存中读取新值。而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值。

​	通过`synchronized`和`Lock`也能保证可见性，Java内存模型规范中规定，线程解锁前，必须把共享变量的最新值刷新到主内存，线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值（加锁与解锁是同一把锁）。



###  volatile关键字原理关键字原理



​	volatile是通过**内存屏障**和**禁止指令重排优化**来实现内存可见性的。



#### 内存屏障

- 硬件层的内存屏障分为两种：`Load Barrier` 和 `Store Barrier`即读屏障和写屏障。
- 内存屏障有两个作用：

> 1. 阻止屏障两侧的指令重排序；
> 2. 强制把写缓冲区/高速缓存中的脏数据等写回主内存，让缓存中相应的数据失效。

- 对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据；
- 对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。



####Java内存屏障

​	**内存屏障** （Memory Barrier，或有时叫做内存栅栏，Memory Fence）是一种CPU指令，用于控制特定条件下的重排序和内存可见性问题。Java编译器也会根据内存屏障的规则禁止重排序。

​	内存屏障可以被分为以下几种类型：

​	1.、`LoadLoad`屏障：对于这样的语句`Load1；LoadLoad；Load2`，在`Load2`及后续读取操作要读取的数据被访问前，保证`Load1`要读取的操作被读取完毕。

​	2、`StoreStore`屏障：对于这样的语句`Store1；StoreStore；Store2`，在`Store2`及后续写入操作执行之前，保证`Store1`的写入操作必须写入主存，并对其它处理器可见。

​	3、`LoadStore`屏障：对于这样的语句`Load1；LoadStore；Store2`，在`Store2`及后续写入操作执行之前，保证`Load1`读取的数据读取完毕。

​	4、`StoreLoad`屏障：对于这样的语句`Store1；StoreLoad；Load2`，在`Load2`及后续读取操作读取完毕之前，保证`Store1`的写入操作必须写入完毕，并对其他处理器可见。 **它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能**



#### volatile中内存屏障的使用	

​	在每个`volatile`写操作前插入`StoreStore`屏障，在写操作后插入`StoreLoad`屏障，将工作内存中的共享变量值刷新到主内存中； 在每个`volatile`读操作前插入`LoadLoad`屏障，在读操作后插入`LoadStore`屏障，从主内存中读取共享变量；



####volatile的使用场景

​	只能在有限的一些情形下使用 volatile 变量替代锁。要使 volatile 变量提供理想的线程安全，必须同时满足下面两个条件：

- 对变量的写操作不依赖于当前值。
- 该变量没有包含在具有其他变量的不变式中。

如果只从单个线程写入，那么可以忽略第一个条件。



## 注意

1、缓存一致性（Cache Coherence），解决的是多个缓存副本之间的数据的一致性问题。Java内存模型屏蔽计算机硬件问题，主要来解决并发编程中的原子性、有序性和一致性问题。

[友情链接](https://www.zhihu.com/question/268021813)

2、 volatile关键字原理[ volatile关键字原理](#volatile关键字原理)

3、final语义中的内存屏障

- 对于final域，编译器和CPU会遵循两个排序规则：

> 1. 新建对象过程中，构造体中对final域的初始化写入和这个对象赋值给其他引用变量，这两个操作不能重排序；（废话嘛）
> 2. 初次读包含final域的对象引用和读取这个final域，这两个操作不能重排序；（晦涩，意思就是先赋值引用，再调用final值）

- 总之上面规则的意思可以这样理解，必需保证一个对象的所有final域被写入完毕后才能引用和读取。这也是内存屏障的起的作用：
- 写final域：在编译器写final域完毕，构造体结束之前，会插入一个StoreStore屏障，保证前面的对final写入对其他线程/CPU可见，并阻止重排序。
- 读final域：在上述规则2中，两步操作不能重排序的机理就是在读final域前插入了LoadLoad屏障。
- X86处理器中，由于CPU不会对写-写操作进行重排序，所以StoreStore屏障会被省略；而X86也不会对逻辑上有先后依赖关系的操作进行重排序，所以LoadLoad也会变省略。